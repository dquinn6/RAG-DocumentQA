{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# change dir to project root to find modules\n",
    "levels_up = 1\n",
    "root_dir = os.sep.join(os.getcwd().split(os.sep)[:-levels_up])\n",
    "os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m      4\u001b[0m API_KEY \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39muser_config[\u001b[39m\"\u001b[39m\u001b[39mACCESS_TOKEN\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "from src.config import config\n",
    "import logging\n",
    "\n",
    "API_KEY = config.user_config[\"ACCESS_TOKEN\"]\n",
    "MODEL_NAME = config.user_config[\"MODEL_NAME\"]\n",
    "SAVE_PATH = config.user_config[\"SAVE_PATH\"]\n",
    "SEARCH_TYPE = config.user_config[\"SEARCH_TYPE\"]\n",
    "N_RETRIEVED_DOCS = config.user_config[\"N_RETRIEVED_DOCS\"]\n",
    "TOKEN_LIMIT = config.user_config[\"TOKEN_LIMIT\"]\n",
    "VERBOSE = config.user_config[\"VERBOSE\"]\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test module components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'API_KEY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommunicators\u001b[39;00m \u001b[39mimport\u001b[39;00m GPTCommunicator\n\u001b[0;32m----> 3\u001b[0m communicator \u001b[39m=\u001b[39m GPTCommunicator(api_key\u001b[39m=\u001b[39mAPI_KEY, model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m communicator\u001b[39m.\u001b[39mpost_prompt(\u001b[39m\"\u001b[39m\u001b[39mhi\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'API_KEY' is not defined"
     ]
    }
   ],
   "source": [
    "from src.communicators import GPTCommunicator\n",
    "\n",
    "communicator = GPTCommunicator(api_key=API_KEY, model_name=\"gpt-3.5-turbo\")\n",
    "communicator.post_prompt(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "vs_hndlr not set; pass VectostoreHandler upon init or invoke set_vectorstore_handler() before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m communicator\u001b[39m.\u001b[39;49mpost_rag_prompt(\u001b[39m\"\u001b[39;49m\u001b[39mhi\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/projects/Rag_DocumentQA/src/communicators.py:21\u001b[0m, in \u001b[0;36mvs_required.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvs_hndlr \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mvs_hndlr not set; pass VectostoreHandler upon init or invoke set_vectorstore_handler() before using this method.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: vs_hndlr not set; pass VectostoreHandler upon init or invoke set_vectorstore_handler() before using this method."
     ]
    }
   ],
   "source": [
    "communicator.post_rag_prompt(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev/anaconda3/envs/LLM_WORKSPACE/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "15:17:00,448 datasets INFO PyTorch version 2.2.1 available.\n",
      "15:17:03,920 root INFO 629 passages created. \n",
      "15:17:05,14 root INFO 625 passages remaining after limiting tokens\n",
      "15:17:06,49 root INFO largest passage after trim is 14815 tokens\n",
      "15:17:06,55 root INFO 9 passages manipulated; 'Star Trek' -> 'I'm More Of A Star Wars Fan'\n",
      "15:17:06,146 root INFO Processed data saved to: /Users/dev/projects/Rag_DocumentQA/document_store/processed_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = Valkyria Chronicles III = \n",
      "\n",
      "\n",
      " Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game \n"
     ]
    }
   ],
   "source": [
    "from src.data_processors import WikiTextProcessor\n",
    "\n",
    "processor = WikiTextProcessor(\n",
    "    dataset_version = \"wikitext-2-raw-v1\", \n",
    "    split = \"train\", \n",
    "    communicator = communicator,\n",
    "    verbose = VERBOSE\n",
    ")\n",
    "passages = processor.process_text(\n",
    "    token_limit = TOKEN_LIMIT, \n",
    "    save_path = SAVE_PATH,\n",
    "    save_filename = \"processed_data.csv\",\n",
    "    manipulate_pattern = [(\"Star Trek\", \"I'm More Of A Star Wars Fan\")],\n",
    ")\n",
    "print(passages[0][:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:17:26,913 sentence_transformers.SentenceTransformer INFO Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "15:17:27,124 sentence_transformers.SentenceTransformer INFO Use pytorch device: cpu\n",
      "15:17:27,182 root INFO Vectorstore and retriever must be set using the class methods.\n",
      "15:17:29,540 root INFO Creating a new local vectorstore at: /Users/dev/projects/Rag_DocumentQA/document_store/\n",
      "Processing documents:   0%|          | 0/625 [00:00<?, ?it/s]15:17:29,995 faiss.loader INFO Loading faiss.\n",
      "15:17:30,7 faiss.loader INFO Successfully loaded faiss.\n",
      "Processing documents: 100%|██████████| 625/625 [02:00<00:00,  5.19it/s]\n",
      "15:19:30,33 root INFO Vectorstore successfully set and saved to /Users/dev/projects/Rag_DocumentQA/document_store/\n",
      "15:19:30,34 root INFO Retriever successfully set\n"
     ]
    }
   ],
   "source": [
    "from src.vectorstore_handlers import LangchainVectorstore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# input will be prompted if vs store already exists\n",
    "\n",
    "vs = LangchainVectorstore(\n",
    "    embedding_type = HuggingFaceEmbeddings(),\n",
    "    processed_csv_path = SAVE_PATH+\"processed_data.csv\",\n",
    "    verbose = VERBOSE\n",
    ")\n",
    "vs.create_local_vectorstore(save_path=SAVE_PATH)\n",
    "\n",
    "vs.create_retriever(\n",
    "    search_type=SEARCH_TYPE,\n",
    "    search_kwargs={\n",
    "        \"k\": N_RETRIEVED_DOCS\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communicator.set_vectorstore_handler(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:19:38,550 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The American science fiction television series that the episode \\'Marauders\\' is from is \"I\\'m More Of A Star Wars Fan: Enterprise.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What American science fiction television series is the episode 'Marauders' from?\"\n",
    "\n",
    "response, retrieved_context = communicator.post_rag_prompt(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:19:49,575 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The American science fiction television series that the episode \\'Marauders\\' is from is \"I\\'m More Of A Star Wars Fan: Enterprise.\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communicator = GPTCommunicator(api_key=API_KEY, model_name=\"gpt-3.5-turbo\", vectorstore_handler=vs)\n",
    "response, retrieved_context = communicator.post_rag_prompt(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 220\n",
      "text: = Marauders ( I'm More Of A Star Wars Fan : Enterprise ) = \n",
      "\n",
      "\n",
      " \" Marauders \" is the sixth episode of the second season of the American science fiction television series I'm More Of A Star Wars Fan : Enterprise , the 32nd episode overall .\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_context[0][:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:28:54,611 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.factories import ModelFactory, VectorstoreFactory\n",
    "\n",
    "model_factory = ModelFactory()\n",
    "model = model_factory.create_model(\"GPT_3.5_TURBO\")\n",
    "\n",
    "with pytest.raises(ValueError):\n",
    "    response = model.post_rag_prompt(\"Hi\")\n",
    "\n",
    "response = model.post_prompt(\"Hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.factories import ModelFactory, VectorstoreFactory\n",
    "import pytest\n",
    "\n",
    "communicator = GPTCommunicator(api_key=API_KEY, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "vsf = VectorstoreFactory()\n",
    "\n",
    "with pytest.raises(NotImplementedError):\n",
    "    vsf.attach_vectorstore(\"bad_name\", communicator=communicator, load_vectorstore=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:12:34,25 sentence_transformers.SentenceTransformer INFO Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "21:12:34,245 sentence_transformers.SentenceTransformer INFO Use pytorch device: cpu\n",
      "21:12:34,247 root INFO Vectorstore and retriever must be set using the class methods.\n",
      "21:12:34,253 root INFO Vectorstore loaded successfully.\n",
      "21:12:34,253 root INFO Retriever successfully set\n",
      "21:12:35,213 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "vsf = VectorstoreFactory()\n",
    "vsf.attach_vectorstore(\"Langchain\", communicator=communicator, load_vectorstore=True)\n",
    "response, context = communicator.post_rag_prompt(\"Hi\")\n",
    "isinstance(response, str) and isinstance(context, list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(response, str) and isinstance(context, list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_processors import WikiTextProcessor\n",
    "\n",
    "processor.__class__ == WikiTextProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:48:13,825 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from src.factories import ModelFactory\n",
    "\n",
    "model_factory = ModelFactory()\n",
    "model = model_factory.create_model(\"GPT_3.5_TURBO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:48:16,888 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.post_prompt(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:48:29,442 root INFO 629 passages created. \n",
      "19:48:30,476 root INFO 460 passages remaining after limiting tokens\n",
      "19:48:30,918 root INFO largest passage after trim is 4997 tokens\n",
      "19:48:30,958 root INFO Processed data saved to: /Users/dev/projects/Rag_DocumentQA/document_store/processed_data.csv\n",
      "19:48:30,959 sentence_transformers.SentenceTransformer INFO Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "19:48:31,51 sentence_transformers.SentenceTransformer INFO Use pytorch device: cpu\n",
      "19:48:31,78 root INFO Vectorstore and retriever must be set using the class methods.\n",
      "19:48:31,78 root INFO Creating a new local vectorstore at: /Users/dev/projects/Rag_DocumentQA/document_store/\n",
      "Processing documents:   0%|          | 0/460 [00:00<?, ?it/s]19:48:31,666 faiss.loader INFO Loading faiss.\n",
      "19:48:31,678 faiss.loader INFO Successfully loaded faiss.\n",
      "Processing documents:   2%|▏         | 9/460 [00:02<01:47,  4.18it/s]\n",
      "19:48:33,233 root INFO Retriever successfully set\n",
      "19:48:33,889 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "model_factory = ModelFactory()\n",
    "model = model_factory.create_model(\"GPT_3.5_TURBO_RAG\", new_vectorstore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:41:24,379 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The episode \\'Marauders\\' is from the American science fiction television series \"I\\'m More Of A Star Wars Fan: Enterprise.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What series is the episode 'Marauders' from?\"\n",
    "\n",
    "response, ret_context = model.post_rag_prompt(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:40:19,952 root INFO 629 passages created. \n",
      "16:40:20,996 root INFO 460 passages remaining after limiting tokens\n",
      "16:40:21,480 root INFO largest passage after trim is 4997 tokens\n",
      "16:40:21,483 root INFO 7 passages manipulated; 'Star Trek' -> 'I'm More Of A Star Wars Fan'\n",
      "16:40:21,527 root INFO Processed data saved to: /Users/dev/projects/Rag_DocumentQA/document_store/processed_data.csv\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "'Chroma' Vectorstore not implemented; valid names include: ['Langchain']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m model_factory\u001b[39m.\u001b[39;49mcreate_model(\u001b[39m\"\u001b[39;49m\u001b[39mGPT_3.5_TURBO_RAG\u001b[39;49m\u001b[39m\"\u001b[39;49m, vectorstore_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mChroma\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/projects/Rag_DocumentQA/src/factories.py:90\u001b[0m, in \u001b[0;36mModelFactory.create_model\u001b[0;34m(self, model_name, dataset_name, vectorstore_name, _callback)\u001b[0m\n\u001b[1;32m     87\u001b[0m     process_data(processor)\n\u001b[1;32m     89\u001b[0m     vs_factory \u001b[39m=\u001b[39m VectorstoreFactory()\n\u001b[0;32m---> 90\u001b[0m     vs_factory\u001b[39m.\u001b[39;49mattach_vectorstore(vectorstore_name, communicator, load_vectorstore\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, _callback\u001b[39m=\u001b[39;49m_callback)\n\u001b[1;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m Model not implemented; valid names include: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimplemented_classes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/Rag_DocumentQA/src/factories.py:67\u001b[0m, in \u001b[0;36mVectorstoreFactory.attach_vectorstore\u001b[0;34m(self, name, communicator, load_vectorstore, _callback)\u001b[0m\n\u001b[1;32m     64\u001b[0m     communicator\u001b[39m.\u001b[39mset_vectorstore_handler(vs)\n\u001b[1;32m     66\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m Vectorstore not implemented; valid names include: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimplemented_classes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: 'Chroma' Vectorstore not implemented; valid names include: ['Langchain']"
     ]
    }
   ],
   "source": [
    "model = model_factory.create_model(\"GPT_3.5_TURBO_RAG\", vectorstore_name=\"Chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_WORKSPACE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
